# Offline Reinforcement Learning and Self-Supervised Learning Resources

## Articles and papers

### Offline Reinforcement Learning

* [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems, Sergey Levine et al, UC Berkeley, Google Research, 2020](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/OfflineReinforcementLearningTutorialReviewLevine2020.pdf)

* [A Survey on Offline Reinforcement Learning: Taxonomy, Review and Open Problems, RF Prudencio et al, 2023](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/A_Survey_on_Offline_Reinforcement_Learning-Taxonomy_Review_and_Open_Problems_Prudencio_2023.pdf)

* [Understanding The World Through Action, Sergey Levine, UC Berkeley, 2021](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Understanding_the_World_Through_Action_Levine_2021.pdf)

* [When Should We Prefer Offline Reinforcement Learning Over Behavioral Cloning?, Aviral Kumar et al, UC Berkeley, Google Research, 2022](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/When_Should_We_Prefer_Offline_Reinforcement_Learning_over_Behavioral_Cloning_Kumar_UCBerkeley_2022.pdf)

* [Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction, Aviral Kumar et al, UC Berkeley, Google Brain, 2019](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Stabilizing_Off-Policy_Q-Learning_via_Bootstrapping_Error_Reduction_Kumar_UCBerkeley_2019.pdf)

* [Off-Policy Deep Reinforcement Learning without Exploration, S. Fujimoto et al, 2019](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Off-Policy_Deep_Reinforcement_Learning_without_Exploration_Fujimoto_2019.pdf)

* [Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human Preferences in Dialog, N. Jaques et al, MIT, 2019](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Way_Off-Policy_Batch_Deep_Reinforcement_Learning_of_Implicit_Human_Preferences_in_Dialog_Jaques_MIT_2019.pdf)

* [Weakly-Supervised Reinforcement Learning for Controllable Behavior, L. Lee et al, CMU, NeurIPS, 2020](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/NeurIPS-2020-weakly-supervised-reinforcement-learning-for-controllable-behavior-Paper.pdf)

* [Hierarchical Relative Enthropy Policy Search, Christian Daniel et al, TU Darmstadt, 2000](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Hierarchical_Relative_Entropy_Policy_Search_Kroemer_Daniel_JMLR_2016.pdf)

* [Offline Meta-Reinforcement Learning with Online Self-Supervision, V. Pong et al, UC Berkeley, 2022](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Offline_Meta-Reinforcement_Learning_with_Online_Self-Supervision_pong22a.pdf)

* [Online Relative Entropy Policy Search using Reproducing Kernel Hilbert Space Embeddings, Z. Chen et al, Huawei, 2016](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Online_Relative_Entropy_Policy_Search_using_Reproducing_Kernel_Hilbert_Space_Embeddings_chen_2016.pdf)

* [Should I Run Offline Reinforcement Learning or Behavioral Cloning? Aviral Kumar et al, UC Berkeley, 2021](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/should_i_run_offline_reinforcement_learning_or_behavioral_cloning_kumar_ucberkeley_2021.pdf)

* [Batch Reinforcement Learning, Sascha Lange, Thomas Gabel, Martin Riedmiller, Chapter of "Reinforcement Learning State of Art", 2012](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Lange_Gabel_EtAl_RL-Book-12.pdf)

* [Neural Fitted Q Iteration - First Experiences with a Data Efficient Neural Reinforcement Learning Method (with annotations), M. Riedmiller, 2005](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Neural_Fitted_Q_Iteration-First_Experiences_with_a_Data_Efficient_Neural_Reinforcement_Learning_Method_Riedmiller_2005_annotated.pdf)

### Self-Supervised Learning

* [Cookbook of Self-Supervised Learning, Balestriero, R, Ibrahim, M, et al., 2023](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Cookbook_of_selfsupervised_learning.pdf)

## Online Tutorials and Short Readings

### Meta AI Research blog

* [Self-supervised learning: the dark matter of intelligence](https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/)

### Youtube

* [A General Purpose Navigation Model, Sergey Levine](https://www.youtube.com/watch?v=Bf30cs5MU1I&t=513s)

### Medium 

* Decisions from Data: How Offline Reinforcement Learning Will Change How We Use Machine Learning, Sergey Levine, 2020

    https://medium.com/@sergey.levine/decisions-from-data-how-offline-reinforcement-learning-will-change-how-we-use-ml-24d98cb069b0

    related paper: [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems, Sergey Levine et al, UC Berkeley, Google Research, 2020](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/OfflineReinforcementLearningTutorialReviewLevine2020.pdf)

    related paper: [D4RL: Datasets for Deep Data-Driven Reinforcement Learning, Justin Fu et al, UC Berkeley, 2021](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/D4RL-Datasets_for_Deep_Data-Driven_Reinforcement_Learning_Fu_UCBerkeley_2021.pdf)

* The Monster of Distributional Shift in Offline Reinforcement Learning and How to Pacify it

    https://medium.com/@athanasios.kapoutsis/the-monster-of-distribution-shift-in-offline-rl-and-how-to-pacify-it-4ea9a5db043

    related paper: [Generalization in Humans and Deep Neural Networks, R. Geirhos et al, UoTubingen, 2020](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Generalisation_in_humans_and_deep_neural_networks_Geirhos_2020.pdf)

    related paper: [A Survey on Offline Reinforcement Learning: Taxonomy, Review and Open Problems, RF Prudencio et al, 2023](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/A_Survey_on_Offline_Reinforcement_Learning-Taxonomy_Review_and_Open_Problems_Prudencio_2023.pdf)

    related paper: [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems, Sergey Levine et al, UC Berkeley, Google Research, 2020](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/OfflineReinforcementLearningTutorialReviewLevine2020.pdf)

    related paper: [When Should We Prefer Offline Reinforcement Learning Over Behavioral Cloning?, Aviral Kumar et al, UC Berkeley, Google Research, 2022](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/When_Should_We_Prefer_Offline_Reinforcement_Learning_over_Behavioral_Cloning_Kumar_UCBerkeley_2022.pdf)

    related paper: [Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction, Aviral Kumar et al, UC Berkeley, Google Brain, 2019](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Stabilizing_Off-Policy_Q-Learning_via_Bootstrapping_Error_Reduction_Kumar_UCBerkeley_2019.pdf)

    related paper: [Off-Policy Deep Reinforcement Learning without Exploration, S. Fujimoto et al, 2019](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Off-Policy_Deep_Reinforcement_Learning_without_Exploration_Fujimoto_2019.pdf)

    related paper: [Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human Preferences in Dialog, N. Jaques et al, MIT, 2019](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Way_Off-Policy_Batch_Deep_Reinforcement_Learning_of_Implicit_Human_Preferences_in_Dialog_Jaques_MIT_2019.pdf)

    related paper: [Relative Entropy Policy Search, Jan Peters et al, Max Planck Institute, 2010](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Relative_entropy_policy_search_Peters_MaxPlanck_2010.pdf)

    related paper: [Awac: accelerating online reinforcement learning with offline datasets, A. Nair, UC Berkeley, 2020](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/AWAC-Accelerating_Online_Reinforcement_Learning_with_Offline_Datasets_Nair_2021.pdf)

    related paper: [Advantage-weighted regression: simple and scalable off-policy reinforcement learning, XB Peng et al, UC Berkeley, 2019](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Advantage-Weighted_Regression-Simple_and_Scalable_Off-Policy_Reinforcement_Learning_Peng_UCBerkeley_2019.pdf)

    related paper: [Offline reinforcement learning with implicit q-learning, I. Kostrikov et al, UC Berkeley, 2021](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Offline_Reinforcement_Learning_with_Implicit_Q-Learning_Kostrikov_UCBerkeley_2021.pdf)

    related paper: [Conservative q-learning for offline reinforcement learning, Aviral Kumar et al, UC Berkeley, 2020](https://github.com/dimitarpg13/self_supervised_learning/blob/main/literature/Conservative_Q-Learning_for_Offline_Reinforcement_Learning_Kumar_2020.pdf)

* Curious Agents: An Introduction with Dries Smith

    https://medium.com/@dries.epos/curious-agents-ebfee02ef024

    (code of this series: https://github.com/DriesSmit/CuriousAgents)

* Curious Agents II: Solving MountainCar without Rewards

    https://medium.com/@dries.epos/curious-agents-ii-solving-mountaincar-without-rewards-c49ae2177819

    (code of this series: https://github.com/DriesSmit/CuriousAgents)

* Curious Agents III: BYOL-Explore

    https://medium.com/@dries.epos/curious-agents-iii-byol-explore-93f34fa6146a

    (code of this series: https://github.com/DriesSmit/CuriousAgents)

* Curious Agents IV: BYOL-Hindsight

    https://medium.com/@dries.epos/curious-agents-iv-byol-hindsight-318c559175f0

    (code of this series: https://github.com/DriesSmit/CuriousAgents)

* Understanding the World Through Action: RL as a Foundation for Scalable Self-Supervised Learning with Sergey Levine

    https://medium.com/@sergey.levine/understanding-the-world-through-action-rl-as-a-foundation-for-scalable-self-supervised-learning-636e4e243001

* How Robots Can Learn End-to-End from Data with Sergey Levine

    https://medium.com/@sergey.levine/how-robots-can-learn-end-to-end-from-data-3d879b0a2ba1


* Self-Supervised Learning Using Projection Heads: Boost performance with unlabeled data with Daniel Warfield

    https://towardsdatascience.com/self-supervised-learning-using-projection-heads-b77af3911d33
